{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Executing test script against a given docker container and choosing correct value that's being returned\n",
    "\n",
    "Here `<value>` is the probability of getting a credit card. You need to choose the right one.\n",
    "\n",
    "* 0.3269\n",
    "* 0.5269\n",
    "* 0.7269\n",
    "* 0.9269\n",
    "\n",
    "# Answer to Q1\n",
    "0.7269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the version of kind that you have?\n",
    "\n",
    "Use kind --version to find out.\n",
    "\n",
    "# Answer to Q2\n",
    "kind version 0.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's test if everything works. Use `kubectl` to get the list of running services. \n",
    "\n",
    "What's `CLUSTER-IP` of the service that is already running there?\n",
    "\n",
    "# Answer to Q3\n",
    "10.96.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "To be able to use the docker image we previously created (`zoomcamp-model:hw10`),\n",
    "we need to register it with `kind`.\n",
    "\n",
    "What's the command we need to run for that?\n",
    "\n",
    "* `kind create cluster`\n",
    "* `kind build node-image`\n",
    "* `kind load docker-image`\n",
    "* `kubectl apply`\n",
    "\n",
    "# Answer to Q4\n",
    "`kind load docker-image`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Now let's create a deployment config (e.g. `deployment.yaml`):\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: credit\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: credit\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: credit\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: credit\n",
    "        image: <Image>\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"64Mi\"\n",
    "            cpu: \"100m\"            \n",
    "          limits:\n",
    "            memory: <Memory>\n",
    "            cpu: <CPU>\n",
    "        ports:\n",
    "        - containerPort: <Port>\n",
    "```\n",
    "\n",
    "Replace `<Image>`, `<Memory>`, `<CPU>`, `<Port>` with the correct values.\n",
    "\n",
    "What is the value for `<Port>`?\n",
    "\n",
    "Apply this deployment using the appropriate command and get a list of running Pods. \n",
    "You can see one running Pod.`\n",
    "\n",
    "# Answer to Q5\n",
    "9696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's create a service for this deployment (`service.yaml`):\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: <Service name>\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: <???>\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: <PORT>\n",
    "```\n",
    "\n",
    "Fill it in. What do we need to write instead of `<???>`?\n",
    "\n",
    "Apply this config file.\n",
    "\n",
    "# Answer to Q6\n",
    "credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Run `kubectl get hpa credit-hpa --watch` command to monitor how the autoscaler performs. \n",
    "Within a minute or so, you should see the higher CPU load; and then - more replicas. \n",
    "What was the maximum amount of the replicas during this test?\n",
    "\n",
    "\n",
    "* 1\n",
    "* 2\n",
    "* 3\n",
    "* 4\n",
    "\n",
    "\n",
    "# Answer to Q7\n",
    "1 - because didn't manage to autoscale (issue on my end)\n",
    "\n",
    "HPA didn' t work as expected - TARGETS show up as <unknown/20%>\n",
    "Debug with `kubectl describe hpa` reveals this\n",
    "```\n",
    "  AbleToScale    True    SucceededGetScale        the HPA controller was able to get the target's current scale\n",
    "  ScalingActive  False   FailedGetResourceMetric  the HPA was unable to compute the replica count: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)\n",
    "Events:\n",
    "  Type     Reason                        Age                    From                       Message\n",
    "  ----     ------                        ----                   ----                       -------\n",
    "  Warning  FailedGetResourceMetric       5m30s (x2 over 5m45s)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)\n",
    "  Warning  FailedComputeMetricsReplicas  5m30s (x2 over 5m45s)  horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu resource metric value: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)\n",
    "  Warning  FailedComputeMetricsReplicas  3m (x10 over 5m15s)    horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu resource metric value: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)\n",
    "  Warning  FailedGetResourceMetric       45s (x19 over 5m15s)   horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
