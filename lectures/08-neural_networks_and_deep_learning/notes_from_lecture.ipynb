{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "[[[177 169  97]\n",
      "  [178 169 100]\n",
      "  [182 173 104]\n",
      "  ...\n",
      "  [251 253 250]\n",
      "  [251 253 248]\n",
      "  [251 254 247]]\n",
      "\n",
      " [[200 190 128]\n",
      "  [203 193 132]\n",
      "  [203 193 132]\n",
      "  ...\n",
      "  [250 251 246]\n",
      "  [250 251 245]\n",
      "  [250 251 245]]\n",
      "\n",
      " [[200 189 133]\n",
      "  [203 192 136]\n",
      "  [202 191 135]\n",
      "  ...\n",
      "  [253 250 245]\n",
      "  [252 249 242]\n",
      "  [251 248 239]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[171 157  82]\n",
      "  [170 156  81]\n",
      "  [171 157  82]\n",
      "  ...\n",
      "  [184 142  32]\n",
      "  [180 133  25]\n",
      "  [182 135  27]]\n",
      "\n",
      " [[171 157  82]\n",
      "  [170 156  81]\n",
      "  [171 157  82]\n",
      "  ...\n",
      "  [187 144  32]\n",
      "  [179 132  24]\n",
      "  [181 134  26]]\n",
      "\n",
      " [[170 156  81]\n",
      "  [171 157  82]\n",
      "  [170 156  81]\n",
      "  ...\n",
      "  [184 138  26]\n",
      "  [182 134  23]\n",
      "  [181 133  22]]]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../clothing-dataset-small/train/t-shirt/5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg\"\n",
    "# Neural network expects image of certain size (usually 299^2, 224^2 or 150^2)\n",
    "img = load_img(file_path, target_size=(150, 150))\n",
    "# Uses PIL\n",
    "# IMG consists is an array that has 3 channels (R, G, B) - each channel contains a representation of pixels with the appropriate value from this channel\n",
    "# Images are encoded internally - array of image size and 3 channels - e.g. (150, 150, 3)\n",
    "# Can transform PIL image into Numpy array, where each row is a pixel - [[[177 169  97], and we have 15 of them\n",
    "x = np.array(img)\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Pre-trained convolutional neural networks\n",
    "- Imagenet dataset: https://www.image-net.org/\n",
    "- Pre-trained models: https://keras.io/api/applications/\n",
    "- Using SaturnCloud for running models in cloud - with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp-9FM8Shbn-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
